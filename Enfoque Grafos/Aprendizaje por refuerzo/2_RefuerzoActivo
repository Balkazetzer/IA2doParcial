import numpy as np

def aprendizaje_activo(estados, acciones, transiciones, recompensas, gamma=0.9, epsilon=0.1, episodios=1000):
    # Inicializar la tabla Q
    Q = np.zeros((len(estados), len(acciones)))

    for _ in range(episodios):
        s = np.random.choice(estados)
        while True:
            if np.random.rand() < epsilon:
                a = np.random.choice(acciones)
            else:
                a = np.argmax(Q[s])

            s_siguiente = np.random.choice(estados, p=transiciones[s, a])
            r = recompensas[s, a]

            # Actualizar la tabla Q
            Q[s, a] = Q[s, a] + 0.1 * (r + gamma * np.max(Q[s_siguiente]) - Q[s, a])

            s = s_siguiente
            if np.max(Q[s]) == 0:
                break

    return Q

# Ejemplo de uso
estados = [0, 1]
acciones = [0, 1]
transiciones = np.array([[[0.8, 0.2], [0.4, 0.6]], [[0.7, 0.3], [0.9, 0.1]]])
recompensas = np.array([[10, 5], [6, 8]])
Q = aprendizaje_activo(estados, acciones, transiciones, recompensas)
print("Tabla Q (Aprendizaje Activo):\n", Q)
