import numpy as np

def q_learning(estados, acciones, transiciones, recompensas, gamma=0.9, alpha=0.1, epsilon=0.1, episodios=1000):
    Q = np.zeros((len(estados), len(acciones)))

    for _ in range(episodios):
        s = np.random.choice(estados)
        while True:
            if np.random.rand() < epsilon:
                a = np.random.choice(acciones)
            else:
                a = np.argmax(Q[s])

            s_siguiente = np.random.choice(estados, p=transiciones[s, a])
            r = recompensas[s, a]

            # Actualizar la tabla Q
            Q[s, a] = Q[s, a] + alpha * (r + gamma * np.max(Q[s_siguiente]) - Q[s, a])

            s = s_siguiente
            if np.max(Q[s]) == 0:
                break

    return Q

